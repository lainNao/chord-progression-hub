■目次
  ＜一般＞
    DB選定                    //spec-20240203012054
    マイグレーションツール選定    //spec-20240203012058
    テーブル定義               //spec-20240203012101
  ＜他＞
    コード進行検索のインデックス    //spec-20240203012412
    2222555511116666みたいな長いコード進行も「2516」で検索引っかかるようにしたい    //spec-20240203012415

■詳細
  ＜2222555511116666みたいな長いコード進行も「2516」で検索引っかかるようにしたい＞
    ■決定
      fuzzyサーチモードとstrictサーチモードを切り替えられるようにする
    ■調査メモ
      ・かといって4444444411116666のDBに入れるデータを「416」とかにしたら「1416」と検索しても引っかかっちゃうからそういうのは嫌だなどうすればいいかな
        ・嫌じゃないかも
        ・なんだかんだ連続が担保されてればいいのかな
      ・いやこういうのはそもそも2516で登録すればいいのでは？
      ・あーでも課題を思いついた「1-4-5-1」を検索したい時、「1-4-4-4-4-4-4-4-5-1」なコードまで引っかかると面倒だと思う
        ・どうしよう、やっぱカンマとハイフンも差をつけたほうがいいのかな…？
          ・またはfuzzyサーチとstrictサーチを切り替えられるようにするか…？それがよさそう…
      ＜思った＞
        ・あと、もし「1444451」も「1451」で引っかかるようにしたいなら、検索用データも「1451」に整形してから入れちゃえばよさそう
        ・そっちのほうがDB容量的な意味でも効率的
  ＜コード進行検索のインデックス＞(spec-20240203010550)
    ■決定
      ・コード進行のデータは（うまく行ったらだけども）億を超えるはずで、10万行フルスキャンした結果が平均0.数秒だったのを踏まえたら、100万件あたりからパフォーマンスや付随的に料金的に破綻してきそうなので、工夫したい
      ・パフォーマンスを上げるために以下の対応をする
        ■定義
        ・PostgreSQLのtsvectorカラム（to_tsvector('simple')）にGinインデックスを貼る。
        ・また、「機能」「コード進行（テンションなし）」「コード進行（テンションあり）」等の検索用の非正規化したデータを格納するテーブルをいくつか作り、そこに対して全文検索をかけるようにする
        ■insert時
        ・そのカラムにはコードを数値に変換したものを半角スペース区切りで入れる。
        ■検索時
        ・検索時にはそのカラムに対して`@@ to_tsquery(...)`で検索をする。
        ・もしコードの連続を担保したいなら「@@ to_tsquery('数 <-> 数')」とやればいける
    ■調査メモ
      ＜案1：自前インデックス＞
        1. まず、以下のようなオブジェクトをMongoDBとかRedisとかでで持つ。

            ```ts
            /**
            * コードとそれを持つコード進行IDとのマッピングオブジェクト
            */
            type ChordAndChordProgressionIdMap = {
              [chord: string]: {
                [chordProgressionId: string]: true
              }
            }
            ```

        2. で、「ユーザーから入力されたコード達を持つコード進行IDの配列」をHashMap的に頑張って、パフォーマンス的にいい感じに取得するようにする。
        3. 次に、そのコード進行IDの配列をin句で指定して、コード進行カラムに対してlike検索をかける。
            - そうするとある程度絞り込めるので、ある程度2の工程は速いはず。
      ＜案2：ElasticSearchのカスタムアナライザー＞https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-pattern-tokenizer.html
        ・要するにtokenizerをwhitespaceにして、それだけでやればいい
        ・後はコードを半角スペース区切りで入れればインデックスがいい感じにつく
        ・RDBMSに比べて費用が高く、たぶん毎月1万円くらいはかかりそうな情報を目にしたので、これ以上時間を使うのを辞めといた
      ＜案3：postgresqlのtest_parser＞
        ・これもwhitespace区切りでインデックスを作ってくれるやつっぽい
          ・でもこれができるかは環境に寄りそう
            ・というかもう無いっぽい
      ＜案4：データ100万件ごとに別マシンにシャーディングしていき、検索時は全シャードに対して検索をかける＞
        ・まず、`like '%...%'`でのフルスキャンの場合、データが10万件ある状態で検索をかけたら大体0.数秒くらいかかっていた。
        ・ということは10万件ごとにシャーディングする必要が出てきそうだけど、世の中の曲はもっともっと多く、Gracenotaというサービスだと1億曲以上あるらしい
        ・となると、同じくらい曲データが増えるとマシン数が1000台を超え、検索時に1000マシンが動くことになる
        ・となると、料金的にやばい案である
        ・よって、この案は一旦避けたい
      ＜案5：フルスキャンでなくインデックスを効かせる＞
        ・まず要件として①「単一コードでのフルスキャン」　②「複数連続するコードでのフルスキャン」ができることがある。
        ・ただ、通常のコード表現の場合、インデックスがめちゃくちゃになりそうだった（かっことかハイフンとかカンマとかスラッシュとかで区切られてしまう）。
          ・よって、まず一工夫として「コードを数に置き換える（数からコードに戻せるようにはしておく」「その数たちを半角スペース区切りで格納する」ということをする
            ・そうすることで通常のRDBMSでもカスタマイズあまりせずにインデックスをコード毎にtokenizeされた状態で貼れるため
        ・というわけでまずRDBMSでもインデックス自体は使えそうだとなった。そのため各RDBMSを比較してみたら、PostgreSQLが一番良さそうであった。
          ■SQLite
            ＜プロス＞
              ・fts5結構すごい
            ＜コンス＞
              ・さすがにWEBアプリケーションでのSQLiteの利用実績が他社に少ない。prismaがまだ対応していない <https://github.com/prisma/prisma/issues/8106>。よって、エコシステムとか情報量とかの面で罠にハマる懸念がある
          ■MySQL
            ＜プロス＞
              ・PlanetScaleがみんな使っており、なんとなく将来性も（Neonよりは）それなりにありそう
              ・一応可能

                ```sql
                -- 普通にフルテキスト
                ALTER TABLE chord_progressions ADD FULLTEXT INDEXidx_normalized_fulltext (normalized);

                SELECT * FROM chord_progressions WHERE MATCH(normalized) AGAINST('+"121 121715"' IN BOOLEAN MODE);
                ```

            ＜コンス＞
              ・調べてみている限りだけど、MySQLは全文検索用の機能がちょっと少ない？
              ・そして実際レコード数と検索クエリを同一条件にした状態でMySQLで全文検索かけたら、MySQLが20ms、PostgreSQLが3msであった。遅かった

          ■PostgreSQL
            ＜考え＞
              ・`C-Dm(7,3)`のようなものを入れるとDm(7,3)が複数に分割されちゃう
              ・なので、`111 7110707`のように特殊な変換をかまして挿入する
                ・1桁目　・・・1~7（C~B）、8=noChord, 9=unIdentified,sameなら前のと同じのを入れる
                ・2桁目　・・・1~3（b,なし,#）
                ・3桁目　・・・1~4（M,m,dim,aug）
                ・4桁目以降
                  ・6=(
                  ・7=)
                  ・8=,
                  ・9=/
                  ・テンション　・・・1~6の数を使って6進数的にIDを振る
              ・そうすれば、1つ1つのコードが半角スペース区切りでインデックスを作れる
                ・OKでは…？
              ・これ普通に検索するよりも実行時間が1/7くらいになった（100行のテーブルでやってみた限りでは）
                ・素晴らしいのでこれでよさそう…
            ＜プロス＞
              ・一応できる
              ・MySQLより速かった（MySQLの項目参照）

                ```sql
                -- 1. tsvector型のカラムを追加
                ALTER TABLE chord_progressions ADD COLUMN normalized_tsvector tsvector;
                
                -- 2. normalizedカラムのデータを使用してtsvectorカラムを更新
                UPDATE chord_progressions SET normalized_tsvector = to_tsvector('simple', normalized);
                
                -- 3. index作成
                  CREATE INDEX normalized_tsvector_idx ON chord_progressions USING gin(normalized_tsvector);
                
                -- 4. 検索（単一コード）
                `SELECT * FROM chord_progressions WHERE normalized_tsvector @@to_tsquery('111');`

                -- 4. 検索（連続するコード）
                `SELECT * FROM chord_progressions WHERE normalized_tsvector @@to_tsquery('121 <-> 121715');`

                -- 5.テスト
                -- explainしたら`Bitmap ~`と出て効いてるようだった
                -- SELECT ts_debug('simple', '121 121715'); したらちゃんと半角スペスでトークン分割してくれてた
                -- ちゃんと`11`と検索した時に`111`が引っかかったりもしなかった。全部数字だからスペースだけでトークン分割してくれてるっぽいはずだたぶん
                -- これ、カスタム言語的なやつにインデックス効かせたい時は基本的にこの手法で良いのでは無いかな

                ```
      ＜Neo4j＞
        ・詳細は省くが一応できるにはできる
        ・ただ、これはインデックスがどうとかいうものではないのかもしれないし、そんなに速くなる気もしなかった。しかもたぶん高い。なあなあとしているけど、とりあえずこれもSQLiteと同じく「なんとなくの不安がまずでかい」というのがあり、これ以上時間を使うのを辞めといた
        ・neo4jだと以下のようになるっぽいな…？簡単な例だと。（ただ以下の例だとコードのノードが大量にできるので、コードは共通のノードとして使い回すようにするのも検討できるならしたいな。そっちのほうがクエリは複雑になるっぽいけども…？）

        ```js
        // まず https://hub.docker.com/_/neo4j を参考にneo4j起動
        // http://localhost:7474にアクセスして、neo4j/neo4jでログイン
        // パスワードを適当に変えてダッシュボードにアクセスして以下を発行

        // 曲A「C-F-G-C」を登録
        CREATE (a:Song {title: 'Song A'})
        CREATE (c1:Chord {name: 'C'})
        CREATE (f:Chord {name: 'F'})
        CREATE (g1:Chord {name: 'G'})
        CREATE (c2:Chord {name: 'C'})
        CREATE (a)-[:PROGRESSION]->(c1)-[:NEXT {song: 'Song A'}]->(f)-[:NEXT {song: 'Song A'}]->(g1)-[:NEXT {song: 'Song A'}]->(c2)

        // 曲B「Am-Dm-G-C」を登録
        CREATE (b:Song {title: 'Song B'})
        CREATE (am:Chord {name: 'Am'})
        CREATE (dm:Chord {name: 'Dm'})
        CREATE (g2:Chord {name: 'G'})
        CREATE (c3:Chord {name: 'C'})
        CREATE (b)-[:PROGRESSION]->(am)-[:NEXT {song: 'Song B'}]->(dm)-[:NEXT {song: 'Song B'}]->(g2)-[:NEXT {song: 'Song B'}]->(c3)

        // 「G-C」というコードの流れがある曲一覧を検索
        MATCH (song:Song)-[:PROGRESSION]->(:Chord)-[:NEXT*]->(g:Chord {name: 'G'})-[:NEXT]->(c:Chord {name: 'C'})
        RETURN DISTINCT song.title
        ```


    ■調査メモ2
      ・ちなみに10万件でのlike検索が1秒台で結果返ってきたので、もうとりあえずしばらくはlike検索でいいはずと最初は結論づけていた
  ＜DB選定＞
    ■決定
      Neonとpostgresを使う
    ■調査メモ
      ＜CloudSQL＞
        ・CloudSQLは高いっぽい
      ＜PlanetScale＞
        ・安牌っぽい。ChatGPTに見積もってもらったらCloudSQLよりも結構安った
        ・外部キーは今ベータで対応してるっぽい
      ＜Neon＞
        ・トランザクションがwebsocketで面倒かも？
        ・GCPでまとめたいのであえ外部のを使ったりしたくないな
          ・と思ったけど料金の理由でやっぱ使ってみる
      ＜D1＞
        ・maximum database sizeが2GBと小さい
      ＜Turso＞
        ・sqliteなので特大データで怖いかも。fts5は使いたかったけど、
        ・docker使わないでローカル開発できるかもなのは偉くはある
      ＜Digital Ocean＞
        ・VPS感
      ＜ScaleGrid＞
        どうなんだろう？
      ＜HarperDB＞
        どうなんだろう  ？
  ＜マイグレーションツール選定＞
    ■決定 
      flyway？
    ■調査メモ
      ・Neon使ってるとそうなりそうなので https://neon.tech/docs/guides/flyway
      ・でもPrismaは？
  ＜テーブル定義＞
    DBのエンティティフォルダにあるエンティティがテーブルのイメージで、それをを元にテーブルを作成